{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e8c94a-00a5-444d-8034-3e58e88c4d3c",
   "metadata": {},
   "source": [
    "# LSTMで体のモーションを推定する  \n",
    "## モーションキャプチャ（OptiTrack + Motive）を使用  \n",
    "Unityのゲーム用バージョン"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5d4ad-7542-44af-9a70-a70af862cf04",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ec6901-01b5-4185-8c0a-462825fb8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ライブラリ読み込み \"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afec365-f9bd-4c7f-93d5-dd83cabc4433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\" GPU設定 \"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48808249-1eaa-4828-a2a1-44974f69eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''モーションデータを扱うクラス '''\n",
    "class motion_data():\n",
    "    \n",
    "    # numFrame:取り出すフレーム数、interval:取り出す間隔\n",
    "    def __init__(self, numFrame):\n",
    "        self.filelist = []       # 学習用データのファイルリスト\n",
    "        self.dataset = []        # 学習用データセット（CSVから取得）\n",
    "        self.frameTime = []      # 各フレームの時刻（CSVから取得）\n",
    "        self.feature_len = 10     # 特徴量抽出後のベクトルの長さ（extract_feature関数に合わせて変更する）\n",
    "        self.numFrame = numFrame\n",
    "        \n",
    "    # csvファイルから学習用データを取得\n",
    "    def get_csv_data(self, dirName):\n",
    "        self.dataset = []\n",
    "        self.frameTime = []\n",
    "        dirName = dirName + \"/\"\n",
    "        self.filelist = os.listdir(dirName)\n",
    "        for fileName in self.filelist:\n",
    "            fname = dirName + fileName\n",
    "            # 以下はnpyファイルを読み込むとき\n",
    "            #newdata = np.load(fname)\n",
    "            # 以下はcsvファイルを読み込むとき\n",
    "            skiprows = 7    # skiprowsには先頭の飛ばす行数を指定\n",
    "            csv_data = np.loadtxt(fname, delimiter=',', skiprows=skiprows, encoding=\"utf-8\")\n",
    "            newframeTime = csv_data[:, 1]\n",
    "            newdata = np.array(csv_data[:, 2:])\n",
    "            #newdata = newdata.reshape([csv_data.shape[0], csv_data.shape[1] // 3, 3])\n",
    "            self.dataset.extend([newdata])\n",
    "            self.frameTime.extend([newframeTime])\n",
    "    \n",
    "    # クォータニオンを回転軸と回転角度に分解（現在不使用）\n",
    "    # rotationの中身は(x,y,z,w)のクォータニオン（npベクトル）\n",
    "    # 数式の参照：http://gamemakerlearning.blog.fc2.com/blog-entry-205.html\n",
    "    def toAngleAxis(self, rotation):\n",
    "        angle = 2 * np.arccos(rotation[3])\n",
    "        nx = rotation[0] / np.sin(angle / 2)\n",
    "        ny = rotation[1] / np.sin(angle / 2)\n",
    "        nz = rotation[2] / np.sin(angle / 2)\n",
    "        axis = np.array([nx, ny, nz])\n",
    "        return [angle, axis]\n",
    "    \n",
    "    def quaternion_product(self, q, p):\n",
    "        Q = np.array([\n",
    "            [ q[3], -q[2],  q[1],  q[0]],\n",
    "            [ q[2],  q[3], -q[0],  q[1]],\n",
    "            [-q[1],  q[0],  q[3],  q[2]],\n",
    "            [-q[0], -q[1], -q[2],  q[3]]])\n",
    "        qp = Q @ p\n",
    "        return qp\n",
    "    \n",
    "    # 共役クォータニオンを返す\n",
    "    def quaternion_inverse(self, q):\n",
    "        inverse = np.array([-q[0], -q[1], -q[2], q[3]])\n",
    "        return inverse\n",
    "    \n",
    "    # ベクトルをクォータニオンで回転\n",
    "    # quaternionは(x,y,z,w)の4次元\n",
    "    def quaternion_rotate_vector(self, vector, quaternion):\n",
    "        v = np.array([vector[0], vector[1], vector[2], 0])\n",
    "        q1 = quaternion.copy()    # 縦ベクトルにする\n",
    "        q2 = self.quaternion_inverse(quaternion)\n",
    "        q3 = self.quaternion_product(q1, v)\n",
    "        ans = self.quaternion_product(q3, q2)\n",
    "        return np.array([ans[0], ans[1], ans[2]])\n",
    "    \n",
    "    # 前額面・矢状面に投影したときの関節角度を返す\n",
    "    # rotationの中身は(x,y,z,w)のクォータニオン（npベクトル）\n",
    "    def frontal_sagittal_plane_angle(self, rotation):\n",
    "        # (0,1,0)がrotationでどこへ移動するか\n",
    "        # y軸回りの回転は検知できないが、前額面・矢状面ではどっちにしろx軸回りの回転を検知できないため問題ない\n",
    "        v = self.quaternion_rotate_vector(np.array([0, 1, 0]), rotation)\n",
    "        #print(v)\n",
    "        frontal_angle = np.arctan2(v[0], v[1])\n",
    "        sagittal_angle = np.arctan2(v[2], v[1])\n",
    "        return frontal_angle, sagittal_angle\n",
    "            \n",
    "    # 特徴量抽出を行う関数\n",
    "    # 圧縮後の次元数がself.feature_lenになるように注意\n",
    "    # 引数：1時刻のデータ\n",
    "    def extract_feature(self, data):\n",
    "        # 必要なモーキャプデータのみ取り出す\n",
    "        bone_data = data[0:91]    # boneのデータを抽出（上半身）\n",
    "        vec7_data = bone_data.reshape([len(bone_data) // 7, 7])    # 座標(x,y,z)、回転(x,y,z,w)の7次元に変換\n",
    "        rotation = vec7_data[:, 0:4]    # 座標データは使わない、回転(x,y,z,w)のみ\n",
    "        # すべてのボーンは使用せず、一部のボーンだけ使用する\n",
    "        chest = rotation[2]\n",
    "        lu_arm = rotation[6]\n",
    "        lf_arm = rotation[7]\n",
    "        ru_arm = rotation[10]\n",
    "        rf_arm = rotation[11]\n",
    "        # 前額面での角度\n",
    "        chest_fAng, chest_sAng = self.frontal_sagittal_plane_angle(chest)\n",
    "        lu_arm_fAng, lu_arm_sAng = self.frontal_sagittal_plane_angle(lu_arm)\n",
    "        lf_arm_fAng, lf_arm_sAng = self.frontal_sagittal_plane_angle(lf_arm)\n",
    "        ru_arm_fAng, ru_arm_sAng = self.frontal_sagittal_plane_angle(ru_arm)\n",
    "        rf_arm_fAng, rf_arm_sAng = self.frontal_sagittal_plane_angle(rf_arm)\n",
    "        retData = [chest_fAng, lu_arm_fAng, lf_arm_fAng, ru_arm_fAng, rf_arm_fAng,\n",
    "                   chest_sAng, lu_arm_sAng, lf_arm_sAng, ru_arm_sAng, rf_arm_sAng]\n",
    "        return retData\n",
    "    \n",
    "    # モーションデータの中から引数intervalの間隔でデータを取り出し\n",
    "    # それを複数パターンでndarray化して返す\n",
    "    def split_interval_data(self, data, interval):\n",
    "        numData = len(data) - (interval * (self.numFrame - 1))\n",
    "        if (numData <= 0):\n",
    "            return None\n",
    "        retData = np.empty((numData, self.numFrame, self.feature_len))\n",
    "        for i in range(numData):\n",
    "            splitData = np.empty((self.numFrame, self.feature_len))    # 分割データの保存先\n",
    "            for j in range(self.numFrame):\n",
    "                splitData[j] = self.extract_feature(data[i + interval * j])\n",
    "            retData[i] = splitData\n",
    "        return retData\n",
    "\n",
    "    # モーションデータをminIntervalから最大のインターバルで間引きしたnumFrameの長さのデータセットを返す\n",
    "    # これにより様々な速さのモーションデータセットを得る\n",
    "    def get_interval_data(self, minInterval, correctID, maxInterval=-1):\n",
    "        numMotion = len(self.dataset)\n",
    "        dataset = np.empty((0, self.numFrame, self.feature_len))\n",
    "        for i in range(numMotion):    # すべてのモーションデータセットに対して\n",
    "            if maxInterval < 0:\n",
    "                maxInterval = (len(self.dataset[i]) - 1) // (self.numFrame - 1)\n",
    "            for interval in range(minInterval, maxInterval + 1):\n",
    "                splitdata = self.split_interval_data(self.dataset[i], interval)\n",
    "                if splitdata is not None:\n",
    "                    dataset = np.concatenate([dataset, splitdata])\n",
    "        correct_data = np.ones(len(dataset), dtype=np.int64) * correctID\n",
    "        return [dataset, correct_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29163d8d-9c8d-4f52-a342-0b7e0dfae0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モーションデータのオブジェクト\n",
    "numFrame = 12     # モーションデータのフレーム数\n",
    "interval = 2      # モーションデータを何フレームに一度取り出すか\n",
    "maxInterval = 4\n",
    "motion_count = 4\n",
    "m = []\n",
    "for i in range(motion_count):\n",
    "    m.append(motion_data(numFrame))     # モーションのデータオブジェクト\n",
    "    \n",
    "#print(m[0].frontal_sagittal_plane_angle(np.array([-0.14832, -0.35363, 0.35720, 0.85168])))\n",
    "#print(m[0].frontal_sagittal_plane_angle(np.array([0.00000, 0.00000, 0.38268, 0.92388])))\n",
    "#print(m[0].frontal_sagittal_plane_angle(np.array([-0.027334,0.023318,-0.027962,0.998963])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3bdae23-8374-4904-b725-57563f9a5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" LSTMのモデルクラス \"\"\"\n",
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.feature_size = 10          # 特徴量x(t)の次元\n",
    "        self.hidden_layer_size = 30    # 隠れ層のサイズ\n",
    "        self.lstm_layers = 1           # LSTMのレイヤー数　(LSTMを何層重ねるか)\n",
    "        self.output_size = 4           # 出力層のサイズ\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(self.feature_size, \n",
    "                                  self.hidden_layer_size, \n",
    "                                  num_layers = self.lstm_layers)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(self.hidden_layer_size, self.output_size)\n",
    "        \n",
    "    def init_hidden_cell(self, batch_size): # LSTMの隠れ層 hidden と記憶セル cell を初期化\n",
    "        hedden = torch.zeros(self.lstm_layers, batch_size, self.hidden_layer_size)\n",
    "        cell = torch.zeros(self.lstm_layers, batch_size, self.hidden_layer_size)        \n",
    "        return (hedden, cell)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        self.hidden_cell = self.init_hidden_cell(batch_size)\n",
    "        x = x.permute(1, 0, 2)                                   # (Batch, Seqence, Feature) -> (Seqence , Batch, Feature)\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(x, self.hidden_cell)    # LSTMの入力データのShapeは(Seqence, Batch, Feature)\n",
    "                                                                 # (h_n) のShapeは (num_layers, batch, hidden_size)\n",
    "        x = h_n[-1,:,:]                                          # lstm_layersの最後のレイヤーを取り出す  (B, h)\n",
    "                                                                 # lstm_outの最後尾と同じ？\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42afd015-3499-4c2b-8259-b1e587cac294",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d08d2c-b5d9-4f7b-8aeb-c738d5b88db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motion:0 Processing data...\n",
      "Motion:1 Processing data...\n",
      "Motion:2 Processing data...\n",
      "Motion:3 Processing data...\n",
      "Data size: [11976, 17169, 17268, 17142]\n",
      "[[[  -1.92512146   82.8526687    68.05346059 ...   -2.44649434\n",
      "     63.76711057    2.10356247]\n",
      "  [  -1.85287886   82.90238844   68.10230082 ...   -2.80240763\n",
      "     64.44451718    2.62035988]\n",
      "  [  -1.78624262   82.92967758   68.12284921 ...   -3.25403922\n",
      "     65.10485542    3.26375069]\n",
      "  ...\n",
      "  [  -1.45192054   82.96741389   67.9591821  ...   -5.31770533\n",
      "     68.37840188    5.91648767]\n",
      "  [  -1.44793628   82.96583961   67.92801253 ...   -5.36597265\n",
      "     68.49885688    6.21753117]\n",
      "  [  -1.44587957   82.98921291   67.93024777 ...   -5.57193709\n",
      "     68.54969399    6.42759582]]\n",
      "\n",
      " [[   2.98480125   67.66486709   72.62274461 ...  -73.91467744\n",
      "     71.08403131   68.95009664]\n",
      "  [   2.93412174   67.93326828   72.57392737 ...  -73.65363645\n",
      "     70.95063362   68.85222352]\n",
      "  [   2.87692526   68.29368515   72.5499849  ...  -73.37558229\n",
      "     70.78919264   68.7170002 ]\n",
      "  ...\n",
      "  [   3.28118493   70.0631259    71.46444394 ...  -71.38788291\n",
      "     69.8252683    68.03255398]\n",
      "  [   3.44239086   70.33641873   71.33725851 ...  -71.13459218\n",
      "     69.82497696   68.06161354]\n",
      "  [   3.60706614   70.6159156    71.27674524 ...  -70.94431648\n",
      "     69.85885656   68.1291708 ]]\n",
      "\n",
      " [[   4.15773069  108.43990377  114.42287925 ... -160.2869992\n",
      "    143.42768336 -136.50033622]\n",
      "  [   3.97377941  108.29585806  113.77103286 ... -159.8183508\n",
      "    144.62628344 -132.0692873 ]\n",
      "  [   3.72940943  108.09971658  113.21079538 ... -159.05850762\n",
      "    146.30517614 -126.24638723]\n",
      "  ...\n",
      "  [   2.25662435  107.07352077  111.70455348 ... -162.19749744\n",
      "    150.3782814  -113.86908765]\n",
      "  [   2.08675317  106.98489964  111.64219076 ... -161.85683812\n",
      "    150.76011678 -113.04121446]\n",
      "  [   1.92154636  106.88377289  111.60823599 ... -161.33467107\n",
      "    151.02596369 -112.13501152]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   3.91875968   22.37308303   51.38301637 ...  -67.26514993\n",
      "     55.2924708    43.41745535]\n",
      "  [   3.38464118   31.82100303   53.28070633 ...  -67.81182086\n",
      "     58.55016762   45.32469608]\n",
      "  [   3.14565915   39.56662982   53.05548827 ...  -68.44998733\n",
      "     62.58441765   48.84245675]\n",
      "  ...\n",
      "  [   2.77205487   57.01341855   36.02840274 ...  -55.81230166\n",
      "     78.51921773   72.44586368]\n",
      "  [   3.2497401    53.27890976   30.53884749 ...  -52.10861701\n",
      "     79.12123676   74.13858813]\n",
      "  [   3.89805748   49.00323047   24.43351194 ...  -49.01071003\n",
      "     79.32888872   75.11419442]]\n",
      "\n",
      " [[   6.74639484   58.81054981   28.55122227 ...  -59.24463061\n",
      "     84.65697395   81.65504233]\n",
      "  [   5.72737114   59.92182872   33.18574323 ...  -62.65047064\n",
      "     81.60213781   75.28536954]\n",
      "  [   5.11571477   54.14245784   36.29832826 ...  -63.77941302\n",
      "     77.02848361   67.38362555]\n",
      "  ...\n",
      "  [   4.22930856    7.94459296   49.01415468 ...  -72.73307271\n",
      "     54.21437553   36.01755262]\n",
      "  [   3.5046921    17.01794146   49.54118645 ...  -72.44905205\n",
      "     62.49870766   42.72644241]\n",
      "  [   3.16802046   34.30167165   49.31380901 ...  -71.05737458\n",
      "     70.5559023    53.70996828]]\n",
      "\n",
      " [[   2.25935354   60.71861241   33.91726497 ...  -55.82572528\n",
      "     78.10922078   72.54129521]\n",
      "  [   3.20153552   56.96924938   29.26361418 ...  -54.71254424\n",
      "     78.8351684    74.34588218]\n",
      "  [   4.23037163   53.75329634   25.08077351 ...  -53.68715858\n",
      "     79.85342084   75.08890805]\n",
      "  ...\n",
      "  [   3.44846582   67.6830144    41.88502011 ...  -58.48649343\n",
      "     77.60127981   72.08310483]\n",
      "  [   2.77493015   67.89113777   45.40698826 ...  -59.6971866\n",
      "     76.11748651   69.27644826]\n",
      "  [   2.56850332   66.73710908   48.20362929 ...  -60.48932503\n",
      "     74.17670286   65.78481758]]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\"\"\" データの準備 \"\"\"\n",
    "# 訓練データ（とテストデータ）から一度に何個のデータを読み込むかを指定する値\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# モーションデータを取り出して分割\n",
    "m[0].get_csv_data(\"./stop\")\n",
    "m[1].get_csv_data(\"./walk\")\n",
    "m[2].get_csv_data(\"./jump\")\n",
    "m[3].get_csv_data(\"./run\")\n",
    "\n",
    "input_data = []\n",
    "correct_data = []\n",
    "data_size = []\n",
    "for i in range(motion_count):\n",
    "    print(\"Motion:%d Processing data...\" % i)\n",
    "    ms, mc = m[i].get_interval_data(interval, i, maxInterval)\n",
    "    input_data.append(ms)\n",
    "    correct_data.append(mc)\n",
    "    data_size.append(len(mc))\n",
    "print(\"Data size: \" + str(data_size))\n",
    "    \n",
    "# 学習データの数をモーションごとにそろえる（少ないデータの数に合わせる）\n",
    "min_data_size = min(data_size)\n",
    "for i in range(motion_count):\n",
    "    idx = random.sample(list(range(data_size[i])), k=min_data_size)\n",
    "    input_data[i] = (input_data[i])[idx]\n",
    "    correct_data[i] = (correct_data[i])[idx]\n",
    "\n",
    "# 学習用モーションデータと正解ラベルのデータを作成\n",
    "input_data = np.concatenate(input_data)    # リストの要素同士を結合\n",
    "correct_data = np.concatenate(correct_data)\n",
    "\n",
    "np.save('input_data', input_data)\n",
    "np.save('correct_data', correct_data)\n",
    "print(input_data * 180 / np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b97d22-1d36-473f-bb1f-5deb8863c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.load('input_data.npy')\n",
    "correct_data = np.load('correct_data.npy')\n",
    "\n",
    "# テンソルに変換\n",
    "input_data = torch.FloatTensor(input_data)\n",
    "correct_data = torch.LongTensor(correct_data)\n",
    "#input_data = torch.cuda.FloatTensor(input_data)\n",
    "#correct_data = torch.cuda.LongTensor(correct_data)\n",
    "\n",
    "# データセットの準備\n",
    "dataset = torch.utils.data.TensorDataset(input_data, correct_data)\n",
    "# 学習用データと検証用データに分割\n",
    "train_size = int(0.8 * len(dataset))    # 学習用データのサイズ（全体の8割）\n",
    "test_size = len(dataset) - train_size    # 検証用データのサイズ\n",
    "trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "#print(vars(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "899d95db-1855-43e9-a331-c1c7e35fa716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -1.9983,  74.0365,  73.0017,  67.3340,  68.7269,  -2.0990, -78.6486,\n",
      "         -67.2468,  70.8273,  67.2607],\n",
      "        [ -2.0323,  73.9830,  72.9460,  67.2954,  68.6934,  -2.0973, -78.6513,\n",
      "         -67.2347,  70.9136,  67.3599],\n",
      "        [ -2.0685,  73.9326,  72.8851,  67.3235,  68.7239,  -2.0924, -78.6676,\n",
      "         -67.2430,  70.9917,  67.4230],\n",
      "        [ -2.1008,  73.9044,  72.8339,  67.3545,  68.7579,  -2.0812, -78.6973,\n",
      "         -67.2719,  71.1048,  67.5247],\n",
      "        [ -2.1243,  73.9198,  72.8055,  67.3720,  68.7789,  -2.0678, -78.7435,\n",
      "         -67.3019,  71.2491,  67.6932],\n",
      "        [ -2.1548,  73.9699,  72.8021,  67.4538,  68.8427,  -2.0655, -78.8005,\n",
      "         -67.3482,  71.3610,  67.8393],\n",
      "        [ -2.1825,  74.0223,  72.7934,  67.6226,  68.9585,  -2.0670, -78.8512,\n",
      "         -67.3878,  71.4321,  67.9509],\n",
      "        [ -2.2099,  74.0570,  72.7692,  67.7168,  69.0576,  -2.0874, -78.9008,\n",
      "         -67.4083,  71.5243,  68.0395],\n",
      "        [ -2.2417,  74.0884,  72.7458,  67.8457,  69.1812,  -2.0918, -78.9682,\n",
      "         -67.4514,  71.6134,  68.1141],\n",
      "        [ -2.2659,  74.1123,  72.7264,  67.9590,  69.2785,  -2.0815, -79.0333,\n",
      "         -67.5325,  71.6717,  68.1840],\n",
      "        [ -2.2816,  74.1293,  72.7176,  68.0676,  69.3785,  -2.0708, -79.0775,\n",
      "         -67.5971,  71.7317,  68.2556],\n",
      "        [ -2.2982,  74.1622,  72.7293,  68.1329,  69.4386,  -2.0582, -79.1188,\n",
      "         -67.6363,  71.7908,  68.3240]])\n"
     ]
    }
   ],
   "source": [
    "print(input_data[20] * 180 / np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c1e55b4-2283-4a42-819a-eb354b09b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 設定 \"\"\"\n",
    "# モデル作成\n",
    "net = Net().to(device)\n",
    "# 損失関数（計算結果と正解ラベルの誤差を比較、それを基に最適化）\n",
    "criterion = torch.nn.CrossEntropyLoss()  # CrossEntropyLossは損失関数に多クラス分類でよく使われる\n",
    "# 最適化アルゴリズム\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  # SGD（確率的勾配降下法）\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58da21e5-f5d6-4cbb-ae7e-e190b5c6092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1, data: 2000, running_loss: 1.076\n",
      "#1, data: 4000, running_loss: 0.259\n",
      "#1, data: 6000, running_loss: 0.149\n",
      "#1, data: 8000, running_loss: 0.118\n",
      "#1, data: 10000, running_loss: 0.081\n",
      "#1, data: 12000, running_loss: 0.146\n",
      "#1, data: 14000, running_loss: 0.078\n",
      "#1, data: 16000, running_loss: 0.089\n",
      "#1, data: 18000, running_loss: 0.063\n",
      "#1, data: 20000, running_loss: 0.043\n",
      "#1, data: 22000, running_loss: 0.048\n",
      "#1, data: 24000, running_loss: 0.050\n",
      "#1, data: 26000, running_loss: 0.057\n",
      "#1, data: 28000, running_loss: 0.056\n",
      "#1, data: 30000, running_loss: 0.029\n",
      "#1, data: 32000, running_loss: 0.044\n",
      "#1, data: 34000, running_loss: 0.029\n",
      "#1, data: 36000, running_loss: 0.045\n",
      "#1, data: 38000, running_loss: 0.035\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 学習 \"\"\"\n",
    "EPOCHS = 1  # すべての入力に対してn回実行\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    running_loss = 0.0  # 平均値出力用\n",
    "    for count, item in enumerate(trainloader, 1):  # BATCH_SIZEごとに実行するため、このときcountの値を増やす\n",
    "        inputs, labels = item  # trainloader経由でデータを20個取り出す\n",
    "        \n",
    "        # CUDAで使えるようキャスト\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # 重みとバイアスの更新で内部的に使用するデータセット\n",
    "        \n",
    "        # Runs the forward pass with autocasting.\n",
    "        outputs = net(inputs)  # ニューラルネットワークにデータを入力\n",
    "        \n",
    "        loss = criterion(outputs, labels)  # 正解ラベルとの比較\n",
    "\n",
    "        loss.backward()  # 誤差逆伝播\n",
    "        optimizer.step()  # 重みとバイアスの更新\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        times = 100\n",
    "        if count % times == 0:\n",
    "            print(f'#{epoch}, data: {count * BATCH_SIZE}, running_loss: {running_loss / times:1.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "torch.save(net, 'body1.pth')\n",
    "print('Training Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb4515ba-dac4-4489-912c-8248f926bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 3])\n",
      "tensor([1, 0, 3])\n",
      "correct: 9429, accuracy: 9429 / 9581 = 98.41352677173573 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 結果出力 \"\"\"\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print(predicted)\n",
    "print(labels)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += len(outputs)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'correct: {correct}, accuracy: {correct} / {total} = {100 * correct / total} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888fd3e-bc29-46bd-b226-49d96b212e37",
   "metadata": {},
   "source": [
    "### UDPの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b8d0e50-1544-4e99-9d01-2230927666b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from socket import *\n",
    "\n",
    "class udp_client:\n",
    "    def __init__(self, SrcIP=\"127.0.0.1\", SrcPort=11111, DstIP=\"127.0.0.1\", DstPort=22222):\n",
    "        # 送信側アドレスをtupleに格納\n",
    "        self.SrcAddr = (SrcIP, SrcPort)\n",
    "        # 受信側アドレスをtupleに格納\n",
    "        self.DstAddr = (DstIP, DstPort)\n",
    "        \n",
    "        self.BUFSIZE = 1024 \n",
    "\n",
    "        # ソケット作成\n",
    "        self.udpClntSock = socket(AF_INET, SOCK_DGRAM)\n",
    "        # 送信側アドレスでソケットを設定\n",
    "        self.udpClntSock.bind(self.SrcAddr)\n",
    "        \n",
    "    \n",
    "    def __delete__(self):\n",
    "        del self.udpClntSock\n",
    "        \n",
    "        \n",
    "    def send(self, data):\n",
    "        # バイナリに変換\n",
    "        data = data.encode('utf-8')\n",
    "\n",
    "        # 受信側アドレスに送信\n",
    "        self.udpClntSock.sendto(data, self.DstAddr)\n",
    "        \n",
    "        \n",
    "    def receive(self):\n",
    "        data, addr = self.udpClntSock.recvfrom(self.BUFSIZE)\n",
    "        data = data.decode()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9afedb9c-b934-449c-ae81-0c583aaeec24",
   "metadata": {},
   "source": [
    "udp_test = udp_client()\n",
    "while(True):\n",
    "    message = udp_test.receive()\n",
    "    data = message.split(',')\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8aa25450-e5f3-469f-8559-eca023e44f1b",
   "metadata": {},
   "source": [
    "del udp_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c44c7-6759-4302-b274-54cd3114ef83",
   "metadata": {},
   "source": [
    "### リアルタイム認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e28574-a5fd-4a06-b419-93ac1e9290aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import torch\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "\"\"\" GPU設定 \"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\"\"\" 識別 \"\"\"\n",
    "net = torch.load('body1.pth')\n",
    "\n",
    "# Unityへ送るUDP\n",
    "udp = udp_client()\n",
    "\n",
    "test_motion = motion_data(numFrame)\n",
    "test_motion.get_csv_data(\"./test_motion2\")\n",
    "data, _ = test_motion.get_interval_data(interval, 0, interval)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "for index in range(0, len(data), interval):\n",
    "    cv2.imshow(\"Window\", np.zeros([256, 256]))\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:    # Escで終了\n",
    "        break\n",
    "    \n",
    "    # intervalの間最も頻出だったモーションを1位とする\n",
    "    answers = []\n",
    "    for i in range(0, interval):\n",
    "        if index + i >= len(data):\n",
    "            break\n",
    "        motion = np.expand_dims(data[index+i], 0)\n",
    "        motion = torch.FloatTensor(motion)\n",
    "        outputs = net(motion)  # ニューラルネットワークにデータを入力\n",
    "        value, predicted_idx = torch.max(outputs, 1)\n",
    "        answer = int(predicted_idx[0])\n",
    "        answers.append(answer)\n",
    "    \n",
    "    # 最頻値を求める\n",
    "    uniqs, counts = np.unique(answers, return_counts=True)\n",
    "    answer = (uniqs[counts == np.amax(counts)])[0]\n",
    "    clear_output(wait=True)\n",
    "    if (answer == 0):\n",
    "        print(\"stop\")\n",
    "        udp.send(\"stop\")\n",
    "    elif (answer == 1):\n",
    "        print(\"walk\")\n",
    "        udp.send(\"walk\")\n",
    "    elif (answer == 2):\n",
    "        print(\"jump\")\n",
    "        udp.send(\"jump\")\n",
    "    elif (answer == 3):\n",
    "        print(\"run\")\n",
    "        udp.send(\"run\")\n",
    "    else:\n",
    "        print(\"error\")\n",
    "    while (time.time() - start_time < (index + 1) / 120):\n",
    "        time.sleep(0.001)\n",
    "        \n",
    "\n",
    "print(\"finish\")\n",
    "print(time.time() - start_time)\n",
    "cv2.destroyAllWindows()\n",
    "del udp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e7083d3-ef6e-4f64-8832-95026c8a5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "del udp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2603116-e8bb-4f3a-9fa2-486fd7113306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
